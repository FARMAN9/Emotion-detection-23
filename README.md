
Hereâ€™s a **cleaner, more polished** version of your README with better structure, consistent formatting, and a more professional tone:

---

# ðŸŽ­ Emotion Detection using Deep Learning

## ðŸ“Œ Overview

This project classifies **human facial emotions** into one of **seven categories** using a **Deep Convolutional Neural Network (CNN)**.

The model is trained on the **FER-2013 dataset**, published during the **International Conference on Machine Learning (ICML)**.

ðŸ“Š **Dataset Details**:

* **35,887** grayscale images
* Size: **48Ã—48 pixels**
* **7 Emotion Classes**: ðŸ˜  Angry | ðŸ¤¢ Disgusted | ðŸ˜¨ Fearful | ðŸ˜„ Happy | ðŸ˜ Neutral | ðŸ˜¢ Sad | ðŸ˜² Surprised

---

## âš™ï¸ Dependencies

* ðŸ **Python 3**
* ðŸ“¦ [OpenCV](https://opencv.org/)
* ðŸ”¥ [TensorFlow](https://www.tensorflow.org/) (Keras API)

Install required packages:

```bash
pip install -r requirements.txt
```

---

## ðŸš€ Getting Started

### ðŸ“‚ Clone Repository

```bash
git clone 
cd Emotion-detection
```

### ðŸ“¥ Download Dataset

Place the **FER-2013 dataset** inside the `src/data` folder.

---

## ðŸ‹ï¸ Training the Model

Run the following command to train:

```bash
cd src
python emotions.py --mode train
```

* âœ… Trains the CNN on FER-2013 dataset
* âœ… Saves model weights as **`model.h5`**
* âœ… Generates training **accuracy & loss plots**

---

## ðŸ” Using Pre-trained Model


```
emotion_dataset/
   train/
       angry/
           angry1.jpg
           angry2.jpg
           ...
       disgust/
           disgust1.jpg
           disgust2.jpg
           ...
       fear/
           fear1.jpg
           fear2.jpg
           ...
       happy/
           happy1.jpg
           happy2.jpg
           ...
       neutral/
           neutral1.jpg
           neutral2.jpg
           ...
       sad/
           sad1.jpg
           sad2.jpg
           ...
       surprise/
           surprise1.jpg
           surprise2.jpg
           ...
   validation/
       angry/
           angry101.jpg
           ...
       disgust/
           disgust101.jpg
           ...
       fear/
           fear101.jpg
           ...
       happy/
           happy101.jpg
           ...
       neutral/
           neutral101.jpg
           ...
       sad/
           sad101.jpg
           ...
       surprise/
           surprise101.jpg
           ...
```

âœ… **What you need to do:**

* Place images of each **emotion** into its correct folder.
* Keep the **same 7 folders** under both `train/` and `validation/`.
* Make sure filenames are **unique** (no duplicates).

---

### ðŸš€ **Where to get images?**

Here are some free datasets you can download:

* **FER2013** (most popular):
  ðŸ“¥ [Kaggle FER2013 Dataset](https://www.kaggle.com/datasets/msambare/fer2013)

* **CK+ (Cohn-Kanade)**:
  ðŸ“¥ [CK+ Dataset (via Kaggle)](https://www.kaggle.com/datasets/shawon10/ckplus)

* **JAFFE Dataset** (Japanese Female Facial Expression):
  ðŸ“¥ [JAFFE dataset download](https://zenodo.org/record/3451524)

---




You can skip training by downloading the **pre-trained model**:
[ðŸ“¥ Download Model](https://drive.google.com/file/d/1FUn0XNOzf-nQV7QjbBPA6-8GLoHNNgv-/view?usp=sharing)

Then run:

```bash
cd src
python emotions.py --mode display
```

This will:
âœ”ï¸ Start webcam feed
âœ”ï¸ Detect faces using **Haar Cascades**
âœ”ï¸ Classify emotions in **real-time**

---

## ðŸ“ Project Structure

```
Emotion-detection/
â”‚
â”œâ”€â”€ imgs/                   # Plots & visuals
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/               # FER-2013 dataset
â”‚   â”œâ”€â”€ emotions.py         # Main script (train/display)
â”‚   â”œâ”€â”€ haarcascade_frontalface_default.xml
â”‚   â”œâ”€â”€ model.h5            # Saved model weights
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ðŸ“Š Model Performance

* **Architecture**: 4-layer CNN
* **Training Epochs**: 50
* **Test Accuracy**: \~63.2%

ðŸ“ˆ *Accuracy Plot Example:*
![Accuracy plot](imgs/accuracy.png)

---

## ðŸ›  Data Preparation (Optional)

The original [FER-2013 dataset](https://www.kaggle.com/deadskull7/fer2013) is in CSV format.
We converted it into **48Ã—48 PNG images** for training & testing.

* ðŸ“œ See `dataset_prepare.py` for conversion code.
* ðŸ§ª Can be modified for **custom datasets**.

---

## ðŸ”¬ How It Works

1ï¸âƒ£ **Face Detection** â€“ Uses **Haar Cascade** to detect faces.
2ï¸âƒ£ **Preprocessing** â€“ Crops & resizes face to **48Ã—48 grayscale**.
3ï¸âƒ£ **Prediction** â€“ CNN outputs **softmax probabilities** for 7 emotions.
4ï¸âƒ£ **Display** â€“ The predicted emotion is displayed on webcam feed.

---

## ðŸ“š References

> Goodfellow, I., Erhan, D., Carrier, P. L., Courville, A., Mirza, M., Hamner, B., ... & Bengio, Y. (2013).
> *Challenges in Representation Learning: A report on three machine learning contests.*
> arXiv preprint arXiv:1307.0414.

---

âœ… **Would you like me to:**

* Add **badges** (e.g., Python version, TensorFlow version)?
* Include a **sample webcam output screenshot** section?
* Or convert this into a **fancier GitHub README with emojis & banners**?
